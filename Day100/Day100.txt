AI 생성할 필요 없이 서비스를 제공

마이크로서비스 아키텍쳐 <-> 모놀리식 아키텍쳐 (전통적 구조 / 서버에 모든 기능이 다 들어가 있음)
- 기능들이 전부 다 독립된 컴퓨팅 환경에서 돌아가는 환경

개발 시작
프로그래밍 방식 액세스
API Call을 만드는 환경
정의가 되어 있음
http/https 프로토콜 이용
가장 먼저 보는 건 IAM 액세스 키 (인증정보를 담아서 보내야 함)
재사용 방지 (SigV4)

API Call을 직접 생성할 수도 있지만 SDK를 호출해서 사용할 수 있다
Python = boto3

management console, CLI은 SDK를 활용해서 호출

SDK 사용 이유
언어 바인딩
HTTP 요청 서명
기본 탑재하고 있는 복원력 관련 기능
	재시도/오류/시간 제한 로직
페이지 매김 지원


명령창 환경
로컬 호출 = 로그가 남음
EC2로 원격 접속 = 로그가 저장되지 않음

CLI 설치
aws cli 설치 검색 후 

명령창은 내가 누군지 모른다 = configure 명령어로 정보 등록

iam Users 사용자 추가
이번 사용자는 management console 체크 해제
attach policy
	AmazonEC2ReadOnlyAccess 체크

user 정보에 access keys 생성
	cli 체크후 동의사항 체크
	secret access 키는 생성 직후에만 확인 가능 (csv파일로 저장)

cli 환경 설정
ubuntu@WebServer1:~$ aws configure
AWS Access Key ID [None]: user의 access key
AWS Secret Access Key [None]: user의 Secret Access Key
Default region name [None]: ap-northeast-2
Default output format [None]: json

설정 후에는 s3 명령어는 Access Denied로 변경됨

프로그래밍 패턴
동기식
명령이 완료되기를 대기함
비동기식
명령 입력 완료 후 대기를 하지 않고 다음 작업을 이어서 함 (결과 확인이 어려움)
waiter를 사용하여 비동기식

AWS 서비스 오류코드
400 : 애플리케이션의 오류 처리 (format, 권한 확인)
500 : 작업 재시도 (2~3번 정도)

SDK 에러 : 언어마다 예외사항 확인

cloudwatch : 로그 수집, 로그 분석


IntelliJ 환경 실습
AWS Cloud9 : IDE를 Instances에 생성 (비용 발생)
AWS CodeWhisperer : IDE 및 코드 편집기용 AI 기반 코드 생성기 (보안 분석)


권한 부여 시작
요청의 보안 주체 확인 -> 정책으로 보안이 어떻게 구성되어 있는지 확인

자격 증명 기반 정책 - 사용자, 그룹에게 지정하는 정책
리소스 기반 정책 - 리소스에 적어놓는 정책 (s3에 적어둔 정책으로 접근자의 권한 확인 / Principal)
위 두개는 동시에 평가 (허용과 거부가 충돌하면 거부가 우선)

권한 경계
권한을 주는 건 아니나 이 범위를 넘을 수 없다는 테두리만 부여

역할
사용자를 통하여 권한을 부여하기 힘들거나 불가능할 때 사용
유효기한을 가진 임시 권한 부여

로컬에 남아있는 사용자 정보가 넘어갈 수 있어서 역할로 접근하는 것이 보안에 좋다
lambda 함수 서비스는 권한 부여 = 역할

Roles : 역할
create role
aws service : ec2
use case : ec2
next
add permissions : s3readonlyaccess
next
role name : 이름 입력
create role

Maximum session duration : 1 hour (1시간짜리 권한)

서버에 역할을 이용한 권한 부여
서버 체크 후 action -> security -> modify IAM role

.aws
config : 리전, output format
credentials : access key, secret access key

우선순위
1. 코드 또는 CLI 지정
2. 환경 변수
3. 보안 인증 정보파일의 기본 보안 인증 정보 프로파일 (.aws/credentials)
4. 인스턴스 프로파일 (역할)

우선순위 앞의 정보가 없어야 역할을 수행할 수 있다


실습
실습 시작 버튼 클릭 후 5~10분 정도 대기

실습 권한만 부여 되어 있음
리전은 정해져 있다 (리전 변경 불가)

win + r mstsc : 원격 데스크톱 연결
windowsinstanceip를 복사해서 원격 ip주소에 붙여넣기
administrator, 창의 password 붙여넣기


Java 개발 환경 구성

developer 프로파일을 사용하여 AWS CLI 명령을 실행
developer 프로파일 이 연결된 역할 을 확인
-> aws sts get-caller-identity --profile developer

Amazon S3 버킷을 나열
-> aws s3 ls --profile developer

bucketToDelete라는 변수를 생성후 BucketName으로 지정
-> set bucketToDelete=BucketName

이름에 deleteme이 포함된 버킷을 삭제
-> aws s3 rb s3://%bucketToDelete% --profile developer

–debug 옵션
	보안 인증 정보 검색
	제공된 파라미터 구문 분석
	AWS 서버로 전송된 요청 구성
	AWS로 전송된 요청의 내용
	원시 응답의 내용
	서식 지정된 출력
aws s3 rb s3://%bucketToDelete% --profile developer --debug

$policyArn 변수를 지정
aws iam attach-role-policy --policy-arn %policyArn% --role-name notes-application-role --profile developer


스토리지
블록 스토리지
디렉토리를 사용 -> 이것이 깊어지거나 복잡해지면 처리 속도 느림, 생성 크기(2TB), 개수 제약 발생
EBS = 용량을 요청해서 생성 (채워진 용량 상관없이 고정 비용 청구)

파일 스토리지
공유 파일 시스템 
디렉토리를 사용 -> 이것이 깊어지거나 복잡해지면 처리 속도 느림, 생성 크기(2TB), 개수 제약 발생
EFS : Linux
FSx : Windows

객체 스토리지
기본적으로 분산 스토리지 방식
copy가 많이 생성, 내구성이 좋다
디렉토리 개념이 없다, 독립된 오브젝트 방식으로 관리
-> 처리 속도 제약, 생성 크기, 개수 제약 없음

s3
객체 스토리지 방식
파일 1개 = 5TB까지 지원
내구성 -> 지우지 않는 한 사라지지 않는다
버킷 생성 = 나만의 격리 저장공간 생성 (저장되는 데이터는 서로 다른 가용영역으로 분산) / 가용성

인스턴스 만들때 선택된 AMI 저장 방식, aws의 모든 백업 방식 = s3 저장

datalake storage = 생성된 데이터들을 우선 한 곳에 모아둔다

버킷 생성시 리전 설정, 이름 설정(전세계적 단위로 이름이 겹치지 않아야 함 / domain이 겹치지 않아야 하므로 유일해야 함)

이벤트 알림
이벤트 발생시 누군가에게 전달해준다

버전관리
기본적으로 꺼져 있음 (새로 업로드 된 데이터만 유지, 이전 버전들은 자동 삭제)
필요할 때 설정을 키면 된다

public access 상태 = 익명 사용자에게 읽기 전용 권한을 부여

s3 상위 = s3 (하위 명령어 조합)
s3 하위 = s3api

s3 관련 작업 = 매니지먼트 콘솔 화면에서 주로 사용

버킷 생성
AWS Region = 리전 생성 위치
name
위 2개 내용은 고정

ownership
ACL = 접근 제어 / O

Block Public Access
Block all public access = 기본 설정 (보안을 위해 설정)

Bucket Versioning
버전 정보

Default encryption
암호화 설정

기능
object 파일
properties 속성
Intelligent-Tiering Archive configurations = 비용 절감용 파일 관리자가 설정


실습
새 Amazon S3 버킷 생성
AMAZON S3 서비스 클라이언트 생성
S3Client s3 = S3Client.builder()
      .region(labRegion)
      .build();

HEADBUCKET 객체 생성
HeadBucketRequest request = HeadBucketRequest.builder()
         .bucket(bucketName)
         .build();

AMAZON S3 WAITER 생성
S3Waiter s3Waiter = s3Client.waiter();

버킷 생성 요청 빌드
CreateBucketRequest bucketRequest = CreateBucketRequest.builder()
      .bucket(bucketName)
      .build();

Amazon S3에 객체 업로드
메타데이터 태그 할당
Map<String, String> metadata = new HashMap<>();
      metadata.put("x-amz-meta-myVal2", "lab2-testing-upload");

PUTOBJECTREQUEST 빌드
PutObjectRequest putObject = PutObjectRequest.builder()
         .bucket(bucketName)
         .key(objectKey)
         .metadata(metadata)
         .build();

Amazon S3에 저장된 객체의 데이터 처리
GETOBJECTREQUEST 빌드
GetObjectRequest getObjectRequest = GetObjectRequest.builder()
                    .bucket(bucketName)
                    .key(objectKey)
                    .build();

PUTOBJECTREQUEST 빌드
s3.putObject(putObject,
                        RequestBody.fromFile(Paths.get(objectNewKey)));